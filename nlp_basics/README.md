Implement and understand NLP fundamentals.
1. Beam search and greedy search.
2. Working principle:
Input -> Encoder -> (Encoder Out) -> Decoder -> (Decoder Out)
                                                    |
                                                    |
                                                    V
                                                  Linear 
                                                    |
                                                    |
                                                    V
                                                  Softmax -> Charecter Probability -> Output

3. Transformer: e.g. My name is Ram ==> Transformer ==> Amar nam Ram.
Used for NLP such as language models and text classification, frequently used in 
sequence-to-sequence models for applications such as Machine Translation, Text Summarization,
Quenstion-Answering, Named Entity Recognition and Speech Recognition.


